{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    # Define a function to categorize countries\n",
    "    def categorize_country(country):\n",
    "        if country == 'USA':\n",
    "            return 'USA'\n",
    "        elif country == 'CANADA':\n",
    "            return 'CANADA'\n",
    "        elif country == 'GERMANY':\n",
    "            return 'GERMANY'\n",
    "        else:\n",
    "            return 'OTHERS'\n",
    "\n",
    "    # Drop rows with null values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Apply country categorization to 'Sender_Country' and 'Bene_Country' columns\n",
    "    df['Sender_Country'] = df['Sender_Country'].apply(categorize_country)\n",
    "    df['Bene_Country'] = df['Bene_Country'].apply(categorize_country)\n",
    "\n",
    "    # Extract sender type and bene type from respective IDs\n",
    "    df[\"Sender_Type\"] = df[\"Sender_Id\"].apply(lambda sender_id: \"-\".join(sender_id.split(\"-\")[:-1]) if \"-\" in sender_id else sender_id)\n",
    "    df[\"Bene_Type\"] = df[\"Bene_Id\"].apply(lambda sender_id: \"-\".join(sender_id.split(\"-\")[:-1]) if \"-\" in sender_id else sender_id)\n",
    "\n",
    "    # Split 'Time_step' into 'Date' and 'Time', then convert 'Time' to seconds\n",
    "    df['Date'] = df['Time_step'].str.split(\" \").str[0]\n",
    "    df['Time'] = df['Time_step'].str.split(\" \").str[1]\n",
    "    df['Time'] = df['Time'].apply(lambda x: int(x.split(\":\")[0]) * 3600 + int(x.split(\":\")[1]) * 60 + int(x.split(\":\")[2]))\n",
    "\n",
    "    # Extract 'Year', 'Month', and 'Day' from 'Date'\n",
    "    df[['Year', 'Month', 'Day']] = df['Date'].str.split('-', expand=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(['Transaction_Id','Time_step','Sender_Id','Sender_Account','Sender_lob','Bene_Id','Bene_Account','Date'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_df(df):\n",
    "\n",
    "    # Initialize StandardScaler\n",
    "    scaler_standard = StandardScaler()\n",
    "\n",
    "    # Fit and transform the data\n",
    "    df['Time_Scaled_Standard'] = scaler_standard.fit_transform(df[['Time']])\n",
    "    with open('scaler_standard_Time.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_standard, f)\n",
    "    \n",
    "    # Initialize MinMaxScaler\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "\n",
    "    # Fit and transform the data\n",
    "    df['Year_MinMax'] = scaler_minmax.fit_transform(df[['Year']])\n",
    "    with open('scaler_minmax_Year.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_minmax, f)\n",
    "\n",
    "    df['Month_MinMax'] = scaler_minmax.fit_transform(df[['Month']])\n",
    "    with open('scaler_minmax_Month.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_minmax, f)\n",
    "    \n",
    "    df['Day_MinMax'] = scaler_minmax.fit_transform(df[['Day']])\n",
    "    with open('scaler_minmax_Day.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler_minmax, f)\n",
    "\n",
    "    df.drop(['Time','Year', 'Month', 'Day'],axis=1,inplace=True)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(df):\n",
    "\n",
    "    # Use one-hot encoding for categorical columns\n",
    "    df = pd.get_dummies(df, columns=['Sender_Country', 'Bene_Country', 'Transaction_Type', 'Sender_Type', 'Bene_Type'], dtype=int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df):\n",
    "    # Assuming your data is in a DataFrame called 'data'\n",
    "    X = df.drop('Label', axis=1)\n",
    "    y = df['Label']\n",
    "\n",
    "    # Using SMOTE to oversample the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Creating a new balanced DataFrame\n",
    "    df = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled, columns=['Label'])], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame, specifying the file path using a raw string literal to handle backslashes\n",
    "data = pd.read_csv(r\"C:\\Users\\gagan\\Downloads\\Data\\Winter 23-24\\Capstone\\Dataset\\fraud_payment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the 'transform_df' function to preprocess the data by performing various transformations (explained in the comments of the 'transform_df' function)\n",
    "# Then, apply the 'scaling_df' function to scale the transformed data (assuming 'scaling_df' is a function defined elsewhere)\n",
    "# Finally, apply the 'encode_df' function to perform one-hot encoding on the preprocessed and scaled data (assuming 'encode_df' is a function defined elsewhere)\n",
    "data = encode_df(scaling_df(transform_df(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Isolation Forest\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.67      0.79    833455\n",
      "           1       0.02      0.38      0.04     17263\n",
      "\n",
      "    accuracy                           0.66    850718\n",
      "   macro avg       0.50      0.52      0.42    850718\n",
      "weighted avg       0.96      0.66      0.78    850718\n",
      "\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.67      0.79    208381\n",
      "           1       0.02      0.40      0.05      4299\n",
      "\n",
      "    accuracy                           0.66    212680\n",
      "   macro avg       0.50      0.53      0.42    212680\n",
      "weighted avg       0.96      0.66      0.78    212680\n",
      "\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Local Outlier Factor\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98    833455\n",
      "           1       0.03      0.02      0.03     17263\n",
      "\n",
      "    accuracy                           0.97    850718\n",
      "   macro avg       0.51      0.50      0.51    850718\n",
      "weighted avg       0.96      0.97      0.96    850718\n",
      "\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    208381\n",
      "           1       0.03      0.03      0.03      4299\n",
      "\n",
      "    accuracy                           0.96    212680\n",
      "   macro avg       0.51      0.51      0.51    212680\n",
      "weighted avg       0.96      0.96      0.96    212680\n",
      "\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Label', axis=1)  # Features\n",
    "y = data['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Isolation Forest': IsolationForest(random_state=42),\n",
    "    'Local Outlier Factor': LocalOutlierFactor(novelty=True),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Convert outlier predictions to 0s and 1s\n",
    "    y_pred_train[y_pred_train == 1] = 0  # Inliers\n",
    "    y_pred_train[y_pred_train == -1] = 1  # Outliers\n",
    "    y_pred_test[y_pred_test == 1] = 0  # Inliers\n",
    "    y_pred_test[y_pred_test == -1] = 1  # Outliers\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Training Classification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"Testing Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10634/10634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 572us/step - loss: 29910618.0000 - val_loss: 29683346.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m10634/10634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 551us/step - loss: 29919322.0000 - val_loss: 29683346.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m10634/10634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 532us/step - loss: 29938606.0000 - val_loss: 29683346.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m10634/10634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 522us/step - loss: 29822668.0000 - val_loss: 29683346.0000\n",
      "\u001b[1m26585/26585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 346us/step\n",
      "\u001b[1m6647/6647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 345us/step\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96    833455\n",
      "           1       0.02      0.05      0.03     17263\n",
      "\n",
      "    accuracy                           0.93    850718\n",
      "   macro avg       0.50      0.50      0.50    850718\n",
      "weighted avg       0.96      0.93      0.95    850718\n",
      "\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96    208381\n",
      "           1       0.02      0.05      0.03      4299\n",
      "\n",
      "    accuracy                           0.93    212680\n",
      "   macro avg       0.50      0.50      0.50    212680\n",
      "weighted avg       0.96      0.93      0.95    212680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Label', axis=1)  # Features\n",
    "y = data['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the autoencoder model\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 32  # You can adjust this as needed\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder model\n",
    "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=64, shuffle=True, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Use the trained autoencoder to reconstruct the data\n",
    "X_train_pred = autoencoder.predict(X_train)\n",
    "X_test_pred = autoencoder.predict(X_test)\n",
    "\n",
    "# Calculate reconstruction errors\n",
    "train_mse = tf.reduce_mean(tf.square(X_train - X_train_pred), axis=1)\n",
    "test_mse = tf.reduce_mean(tf.square(X_test - X_test_pred), axis=1)\n",
    "\n",
    "# Determine the threshold for anomaly detection (e.g., based on the 95th percentile of training errors)\n",
    "threshold = np.percentile(train_mse, 95)\n",
    "\n",
    "# Predict anomalies based on the threshold\n",
    "y_pred_train = (train_mse > threshold).numpy().astype(int)\n",
    "y_pred_test = (test_mse > threshold).numpy().astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"Testing Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the 'balance_df' function to balance the data (explained in the comments of the 'balance_df' function)\n",
    "data = balance_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('Label', axis=1)  # Features\n",
    "y = data['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree (Regularized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Classification Report (Regularized Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96    729323\n",
      "           1       0.99      0.92      0.95    729247\n",
      "\n",
      "    accuracy                           0.95   1458570\n",
      "   macro avg       0.96      0.95      0.95   1458570\n",
      "weighted avg       0.96      0.95      0.95   1458570\n",
      "\n",
      "Training Data Accuracy Score (Regularized Decision Tree): 0.9548256168713192\n",
      "------------------------------------\n",
      "Test Data Classification Report (Regularized Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96    312513\n",
      "           1       0.99      0.92      0.95    312589\n",
      "\n",
      "    accuracy                           0.95    625102\n",
      "   macro avg       0.96      0.95      0.95    625102\n",
      "weighted avg       0.96      0.95      0.95    625102\n",
      "\n",
      "Test Data Accuracy Score (Regularized Decision Tree): 0.9547657822243409\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train decision tree model with regularization\n",
    "dt_model_regularized = DecisionTreeClassifier(max_depth=8, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
    "dt_model_regularized.fit(X_train, y_train)\n",
    "y_pred_train_regularized = dt_model_regularized.predict(X_train)\n",
    "y_pred_test_regularized = dt_model_regularized.predict(X_test)\n",
    "\n",
    "# pickle.dump(dt_model_regularized, 'model.pkl')\n",
    "\n",
    "# Classification report and accuracy for training data with regularization\n",
    "print(\"Training Data Classification Report (Regularized Decision Tree):\")\n",
    "print(classification_report(y_train, y_pred_train_regularized))\n",
    "print(\"Training Data Accuracy Score (Regularized Decision Tree):\", accuracy_score(y_train, y_pred_train_regularized))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data with regularization\n",
    "print(\"Test Data Classification Report (Regularized Decision Tree):\")\n",
    "print(classification_report(y_test, y_pred_test_regularized))\n",
    "print(\"Test Data Accuracy Score (Regularized Decision Tree):\", accuracy_score(y_test, y_pred_test_regularized))\n",
    "print(\"------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Training Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    729323\n",
      "           1       1.00      0.94      0.97    729247\n",
      "\n",
      "    accuracy                           0.97   1458570\n",
      "   macro avg       0.97      0.97      0.97   1458570\n",
      "weighted avg       0.97      0.97      0.97   1458570\n",
      "\n",
      "AdaBoost Training Data Accuracy Score: 0.970713781306348\n",
      "------------------------------------\n",
      "AdaBoost Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    312513\n",
      "           1       1.00      0.94      0.97    312589\n",
      "\n",
      "    accuracy                           0.97    625102\n",
      "   macro avg       0.97      0.97      0.97    625102\n",
      "weighted avg       0.97      0.97      0.97    625102\n",
      "\n",
      "AdaBoost Test Data Accuracy Score: 0.9709423422097514\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train AdaBoost model\n",
    "ab_model = AdaBoostClassifier(random_state=42)\n",
    "ab_model.fit(X_train, y_train)\n",
    "y_pred_ab = ab_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"AdaBoost Training Data Classification Report:\")\n",
    "print(classification_report(y_train, ab_model.predict(X_train)))\n",
    "print(\"AdaBoost Training Data Accuracy Score:\", accuracy_score(y_train, ab_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"AdaBoost Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ab))\n",
    "print(\"AdaBoost Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_ab))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training Data Classification Report:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.69      0.80    729323\n",
      "           1       0.75      0.96      0.84    729247\n",
      "\n",
      "    accuracy                           0.82   1458570\n",
      "   macro avg       0.85      0.82      0.82   1458570\n",
      "weighted avg       0.85      0.82      0.82   1458570\n",
      "\n",
      "Naive Bayes Training Data Accuracy Score: 0.8232974762952755\n",
      "------------------------------------\n",
      "Naive Bayes Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.69      0.80    312513\n",
      "           1       0.75      0.96      0.84    312589\n",
      "\n",
      "    accuracy                           0.82    625102\n",
      "   macro avg       0.85      0.82      0.82    625102\n",
      "weighted avg       0.85      0.82      0.82    625102\n",
      "\n",
      "Naive Bayes Test Data Accuracy Score: 0.8229121007451584\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"Naive Bayes Training Data Classification Report:\")\n",
    "print(classification_report(y_train, nb_model.predict(X_train)))\n",
    "print(\"Naive Bayes Training Data Accuracy Score:\", accuracy_score(y_train, nb_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"Naive Bayes Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Training Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    729323\n",
      "           1       1.00      0.94      0.97    729247\n",
      "\n",
      "    accuracy                           0.97   1458570\n",
      "   macro avg       0.97      0.97      0.97   1458570\n",
      "weighted avg       0.97      0.97      0.97   1458570\n",
      "\n",
      "Gradient Boosting Training Data Accuracy Score: 0.9685801847014541\n",
      "------------------------------------\n",
      "Gradient Boosting Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    312513\n",
      "           1       1.00      0.94      0.97    312589\n",
      "\n",
      "    accuracy                           0.97    625102\n",
      "   macro avg       0.97      0.97      0.97    625102\n",
      "weighted avg       0.97      0.97      0.97    625102\n",
      "\n",
      "Gradient Boosting Test Data Accuracy Score: 0.9687347024965526\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train gradient boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"Gradient Boosting Training Data Classification Report:\")\n",
    "print(classification_report(y_train, gb_model.predict(X_train)))\n",
    "print(\"Gradient Boosting Training Data Accuracy Score:\", accuracy_score(y_train, gb_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"Gradient Boosting Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"Gradient Boosting Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    729323\n",
      "           1       1.00      1.00      1.00    729247\n",
      "\n",
      "    accuracy                           1.00   1458570\n",
      "   macro avg       1.00      1.00      1.00   1458570\n",
      "weighted avg       1.00      1.00      1.00   1458570\n",
      "\n",
      "Random Forest Training Data Accuracy Score: 0.9999835455274687\n",
      "------------------------------------\n",
      "Random Forest Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    312513\n",
      "           1       1.00      0.98      0.99    312589\n",
      "\n",
      "    accuracy                           0.99    625102\n",
      "   macro avg       0.99      0.99      0.99    625102\n",
      "weighted avg       0.99      0.99      0.99    625102\n",
      "\n",
      "Random Forest Test Data Accuracy Score: 0.9886658497333235\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train random forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"Random Forest Training Data Classification Report:\")\n",
    "print(classification_report(y_train, rf_model.predict(X_train)))\n",
    "print(\"Random Forest Training Data Accuracy Score:\", accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"Random Forest Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron Training Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    729323\n",
      "           1       1.00      0.95      0.97    729247\n",
      "\n",
      "    accuracy                           0.97   1458570\n",
      "   macro avg       0.97      0.97      0.97   1458570\n",
      "weighted avg       0.97      0.97      0.97   1458570\n",
      "\n",
      "Multi-layer Perceptron Training Data Accuracy Score: 0.973478818294631\n",
      "------------------------------------\n",
      "Multi-layer Perceptron Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97    312513\n",
      "           1       1.00      0.95      0.97    312589\n",
      "\n",
      "    accuracy                           0.97    625102\n",
      "   macro avg       0.98      0.97      0.97    625102\n",
      "weighted avg       0.98      0.97      0.97    625102\n",
      "\n",
      "Multi-layer Perceptron Test Data Accuracy Score: 0.9736938931566368\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Multi-layer Perceptron model\n",
    "mlp_model = MLPClassifier(random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"Multi-layer Perceptron Training Data Classification Report:\")\n",
    "print(classification_report(y_train, mlp_model.predict(X_train)))\n",
    "print(\"Multi-layer Perceptron Training Data Accuracy Score:\", accuracy_score(y_train, mlp_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"Multi-layer Perceptron Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(\"Multi-layer Perceptron Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98    729323\n",
      "           1       1.00      0.95      0.97    729247\n",
      "\n",
      "    accuracy                           0.97   1458570\n",
      "   macro avg       0.98      0.97      0.97   1458570\n",
      "weighted avg       0.98      0.97      0.97   1458570\n",
      "\n",
      "Logistic Regression Training Data Accuracy Score: 0.974749240694653\n",
      "------------------------------------\n",
      "Logistic Regression Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98    312513\n",
      "           1       1.00      0.95      0.97    312589\n",
      "\n",
      "    accuracy                           0.98    625102\n",
      "   macro avg       0.98      0.98      0.98    625102\n",
      "weighted avg       0.98      0.98      0.98    625102\n",
      "\n",
      "Logistic Regression Test Data Accuracy Score: 0.9750184769845561\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train logistic regression model\n",
    "lr_model = LogisticRegression(random_state=42,max_iter=10000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Classification report and accuracy for training data\n",
    "print(\"Logistic Regression Training Data Classification Report:\")\n",
    "print(classification_report(y_train, lr_model.predict(X_train)))\n",
    "print(\"Logistic Regression Training Data Accuracy Score:\", accuracy_score(y_train, lr_model.predict(X_train)))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "# Classification report and accuracy for test data\n",
    "print(\"Logistic Regression Test Data Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Test Data Accuracy Score:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
